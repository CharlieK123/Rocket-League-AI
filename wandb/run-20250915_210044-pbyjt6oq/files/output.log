<rlgym_sim.utils.action_parsers.continuous_act.ContinuousAction object at 0x000002956E0F0610>
Process SpawnProcess-8:
Traceback (most recent call last):
  File "C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python39_64\lib\multiprocessing\process.py", line 315, in _bootstrap
    self.run()
  File "C:\Program Files (x86)\Microsoft Visual Studio\Shared\Python39_64\lib\multiprocessing\process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "C:\Users\charl\PycharmProjects\pythonProject10\venv\lib\site-packages\rlgym_ppo\batched_agents\batched_agent.py", line 67, in batched_agent_process
    env = build_env_fn()
  File "C:\Users\charl\PycharmProjects\pythonProject10\gpt.py", line 53, in build_rocketsim_env
    reward_fn = CombinedReward(reward_functions=rewards_to_combine,
  File "C:\Users\charl\PycharmProjects\pythonProject10\venv\lib\site-packages\rlgym_sim\utils\reward_functions\combined_reward.py", line 30, in __init__
    if len(self.reward_functions) != len(self.reward_weights):
TypeError: object of type 'VelocityReward' has no len()
[0m
