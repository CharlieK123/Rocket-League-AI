{"Policy Reward":-11.09953748912854,"Policy Entropy":0.6164798339207967,"Timestep Consumption Time":0.10799009999999498,"Timesteps Collected":5026,"Overall Steps per Second":8705.687987519053,"PPO Batch Consumption Time":0.013347943623860678,"_step":479,"Collected Steps per Second":10708.800733635975,"Timestep Collection Time":0.4693335999999988,"Mean KL Divergence":0.0036243270927419267,"Cumulative Timesteps":706162,"_runtime":1308,"_wandb":{"runtime":1308},"_timestamp":1.7581069851619148e+09,"Total Iteration Time":0.5773236999999938,"SB3 Clip Fraction":0.03313333292802175,"Policy Update Magnitude":0.10025158524513245,"Cumulative Model Updates":198,"z_vel":19.360028954693462,"Value Function Update Magnitude":0.10021475702524185,"y_vel":486.67672786067385,"Value Function Loss":2.393108288447062,"x_vel":-61.96424817484057}