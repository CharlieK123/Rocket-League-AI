{"Timestep Collection Time":3.1089652,"Mean KL Divergence":0.003896304483835896,"_step":650,"z_vel":16.440151982633942,"Value Function Update Magnitude":0.18236537277698517,"Cumulative Model Updates":144,"Collected Steps per Second":16086.381410766515,"_runtime":1736,"x_vel":27.779392691610397,"_wandb":{"runtime":1736},"_timestamp":1.7581079819228108e+09,"y_vel":376.76707131637204,"Policy Entropy":0.7615880966186523,"PPO Batch Consumption Time":0.06357165177663167,"Timesteps Collected":50012,"Policy Reward":0.023891766523420496,"Policy Update Magnitude":0.20446383953094482,"Total Iteration Time":4.30303330000001,"Cumulative Timesteps":1550584,"Overall Steps per Second":11622.498947428523,"Value Function Loss":0.01439861332376798,"Timestep Consumption Time":1.1940681000000097,"SB3 Clip Fraction":0.03995666621873776}